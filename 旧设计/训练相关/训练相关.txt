#各项能力的解决方案
能力项	代码可达成率	训练方案	推荐模型
句子边界	85-90%	可训练序列标注模型	单独的CRF/BiLSTM(初期使用)
敬语识别	60-70%	微调TiBERT（已有28%基础）	TiBERT
语义角色	30-40%	需要大规模标注数据	新的BERT模型
平行结构	70-80%	可用模板+规则解决	不需要训练
训练建议优先级：
微调TiBERT敬语识别（最容易，基础最好）
训练句子分割模型（数据容易标注）
语义角色标注（最难，暂不建议）

#句子边界检测准确率
代码规则处理：
基础规则：70-75%准确率
增强规则（考虑引号、括号等）：80-85%
结合长度和标点综合判断：85-90%
训练可行性：
可行但成本高
需要大量标注数据（至少10万句）
建议先用规则，收集错误案例后再考虑训练


一、三模型训练需求分析
1. TiBERT训练需求
当前问题：

术语识别95%准确率（已经很好）
敬语识别28%（需要提升）
没有句子边界检测能力
训练方向：

Python
# 1. 敬语识别增强
训练数据需求：
- 标注敬语词汇的语料（至少10万句）
- 包含：敬语动词、敬语名词、敬语助词
- 标注格式：{"text": "མཁྱེན་", "is_honorific": true, "type": "verb"}

# 2. 句子边界检测
训练数据需求：
- 标注句子边界的藏文文本
- 特别关注：ང་།、ག།、ད།等结尾
- 需要处理嵌套引用、长句等复杂情况
2. MT5训练需求
当前问题：

语法角色识别33.3%（核心改进点）
复杂度评估有偏差
没有充分利用跨语言能力
训练方向：

Python
# 1. 语法角色识别增强
训练数据需求：
- 藏文句子的语法角色标注（主语、谓语、宾语等）
- 至少5万个句子，覆盖各种句型
- 标注示例：
{
  "sentence": "བླ་མས་ཆོས་གསུངས།",
  "roles": {
    "subject": {"text": "བླ་མ", "position": 0},
    "verb": {"text": "གསུངས", "position": 2},
    "object": {"text": "ཆོས", "position": 1}
  }
}

# 2. 复杂度评估校准
- 需要人工标注的句子复杂度分数
- 包含简单、中等、复杂三个级别
3. NLLB训练需求
当前问题：

术语翻译0%（最严重）
敬语保持0%
过度意译
训练方向：

Python
# 1. 术语保护训练
训练策略：
- 在训练数据中标记术语边界
- 使用特殊标记：<TERM>སངས་རྒྱས་</TERM> → <TERM>佛陀</TERM>
- 训练模型识别并保护这些标记

# 2. 风格迁移训练
- 收集不同风格的平行语料
- 敬语文本 vs 普通文本
- 让模型学习保持原文风格



数据收集优先级
最优先：藏汉平行语料（带术语标注）
次优先：语法角色标注数据
再次：敬语标注数据
最后：句子复杂度标注

# 分阶段训练
Phase1: 基础能力提升（2-3个月）
- TiBERT敬语识别
- MT5语法角色识别
- NLLB术语保护

Phase2: 深度优化（3-6个月）
- 句子边界检测
- 复杂度评估校准
- 风格保持能力

Phase3: 系统整合（1-2个月）
- 三模型协同优化
- 端到端微调


3. 评估指标
Python
metrics = {
    'TiBERT': {
        'honorific_recognition': 0.8,  # 目标80%
        'sentence_boundary': 0.9,      # 目标90%
    },
    'MT5': {
        'grammar_role_accuracy': 0.8,  # 目标80%
        'complexity_correlation': 0.85, # 目标相关度
    },
    'NLLB': {
        'term_preservation': 0.9,      # 目标90%
        'style_consistency': 0.8,      # 目标80%
    }
}